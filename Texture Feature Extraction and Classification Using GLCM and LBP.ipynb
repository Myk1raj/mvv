{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02408862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "# Function to load and preprocess images\n",
    "def load_dataset(base_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Loop through each folder (type1, type2, ...)\n",
    "    for class_idx, folder in enumerate(['type1', 'type2', 'type3', 'type4', 'type5']):\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        print(f\"Loading images from {folder_path}\")\n",
    "        \n",
    "        # Loop through each image in the folder\n",
    "        for filename in tqdm(os.listdir(folder_path)):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                \n",
    "                # Read the image\n",
    "                img = imread(img_path)\n",
    "                \n",
    "                # Convert to grayscale if the image is RGB\n",
    "                if len(img.shape) > 2:\n",
    "                    img = rgb2gray(img)\n",
    "                \n",
    "                # Resize to 256x256\n",
    "                img = resize(img, (256, 256), anti_aliasing=True)\n",
    "                \n",
    "                # Normalize pixel values to [0, 1] if not already\n",
    "                if img.max() > 1.0:\n",
    "                    img = img / 255.0\n",
    "                    \n",
    "                # Add image and label to lists\n",
    "                images.append(img)\n",
    "                labels.append(class_idx)  # Use folder index as label\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load the dataset\n",
    "# Replace 'path_to_your_dataset' with the actual path to your dataset folder\n",
    "dataset_path = '.'  # Current directory, update if needed\n",
    "images, labels = load_dataset(dataset_path)\n",
    "\n",
    "# Display some basic information about the dataset\n",
    "print(f\"Total number of images: {len(images)}\")\n",
    "print(f\"Image shape: {images[0].shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(labels))}\")\n",
    "print(f\"Class distribution: {np.bincount(labels)}\")\n",
    "\n",
    "# Visualize sample images from each class\n",
    "plt.figure(figsize=(15, 10))\n",
    "for class_idx in range(5):  # For each class\n",
    "    # Get indices for this class\n",
    "    class_indices = np.where(labels == class_idx)[0]\n",
    "    \n",
    "    # Select 5 random images from this class\n",
    "    if len(class_indices) >= 5:\n",
    "        sample_indices = np.random.choice(class_indices, 5, replace=False)\n",
    "        \n",
    "        # Plot each image\n",
    "        for i, idx in enumerate(sample_indices):\n",
    "            plt.subplot(5, 5, class_idx*5 + i + 1)\n",
    "            plt.imshow(images[idx], cmap='gray')\n",
    "            plt.title(f\"Type {class_idx+1}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} images\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} images\")\n",
    "def extract_glcm_features(image):\n",
    "    \"\"\"\n",
    "    Extract GLCM features from an image:\n",
    "    - Contrast\n",
    "    - Correlation\n",
    "    - Energy\n",
    "    - Homogeneity\n",
    "    \"\"\"\n",
    "    # Convert floating-point image to uint8 for GLCM calculation\n",
    "    # GLCM requires discrete gray levels\n",
    "    image_uint8 = (image * 255).astype(np.uint8)\n",
    "    \n",
    "    # Calculate GLCM matrix\n",
    "    # distances: [1] - one pixel distance\n",
    "    # angles: [0, np.pi/4, np.pi/2, 3*np.pi/4] - 0째, 45째, 90째, 135째\n",
    "    glcm = graycomatrix(image_uint8, \n",
    "                       distances=[1], \n",
    "                       angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], \n",
    "                       levels=256,\n",
    "                       symmetric=True, \n",
    "                       normed=True)\n",
    "    \n",
    "    # Calculate GLCM properties\n",
    "    contrast = graycoprops(glcm, 'contrast').mean()\n",
    "    correlation = graycoprops(glcm, 'correlation').mean()\n",
    "    energy = graycoprops(glcm, 'energy').mean()\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity').mean()\n",
    "    \n",
    "    # Return features as a list\n",
    "    return [contrast, correlation, energy, homogeneity]\n",
    "\n",
    "# Extract GLCM features for training set\n",
    "print(\"Extracting GLCM features for training images...\")\n",
    "glcm_features_train = np.array([extract_glcm_features(img) for img in tqdm(X_train)])\n",
    "\n",
    "# Extract GLCM features for testing set\n",
    "print(\"Extracting GLCM features for testing images...\")\n",
    "glcm_features_test = np.array([extract_glcm_features(img) for img in tqdm(X_test)])\n",
    "\n",
    "# Display feature shapes\n",
    "print(f\"GLCM training features shape: {glcm_features_train.shape}\")\n",
    "print(f\"GLCM testing features shape: {glcm_features_test.shape}\")\n",
    "\n",
    "# Visualize the GLCM features\n",
    "glcm_feature_names = ['Contrast', 'Correlation', 'Energy', 'Homogeneity']\n",
    "\n",
    "# Create a DataFrame for easy visualization\n",
    "glcm_df = pd.DataFrame(glcm_features_train, columns=glcm_feature_names)\n",
    "glcm_df['Class'] = y_train\n",
    "\n",
    "# Calculate the mean of each feature for each class\n",
    "glcm_class_means = glcm_df.groupby('Class').mean()\n",
    "\n",
    "# Plot the mean values\n",
    "plt.figure(figsize=(12, 6))\n",
    "glcm_class_means.plot(kind='bar', ax=plt.gca())\n",
    "plt.title('Mean GLCM Features by Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Feature Value')\n",
    "plt.legend(title='Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Box plots for each feature across classes\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(glcm_feature_names):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.boxplot(x='Class', y=feature, data=glcm_df)\n",
    "    plt.title(f'Distribution of {feature} by Class')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "def extract_lbp_features(image, num_points=8, radius=1, num_bins=10):\n",
    "    \"\"\"\n",
    "    Extract LBP features from an image\n",
    "    \"\"\"\n",
    "    # Compute LBP\n",
    "    lbp = local_binary_pattern(image, num_points, radius, method='uniform')\n",
    "    \n",
    "    # Compute histogram\n",
    "    n_bins = num_points + 2  # Number of bins for uniform LBP\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "    \n",
    "    return hist\n",
    "\n",
    "# Extract LBP features for training set\n",
    "print(\"Extracting LBP features for training images...\")\n",
    "lbp_features_train = np.array([extract_lbp_features(img) for img in tqdm(X_train)])\n",
    "\n",
    "# Extract LBP features for testing set\n",
    "print(\"Extracting LBP features for testing images...\")\n",
    "lbp_features_test = np.array([extract_lbp_features(img) for img in tqdm(X_test)])\n",
    "\n",
    "# Display feature shapes\n",
    "print(f\"LBP training features shape: {lbp_features_train.shape}\")\n",
    "print(f\"LBP testing features shape: {lbp_features_test.shape}\")\n",
    "\n",
    "# Visualize LBP on a sample image\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Sample image index\n",
    "sample_idx = 0\n",
    "\n",
    "# Original image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(X_train[sample_idx], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# LBP image\n",
    "lbp_image = local_binary_pattern(X_train[sample_idx], 8, 1, method='uniform')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(lbp_image, cmap='gray')\n",
    "plt.title('LBP Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize LBP histograms for different classes\n",
    "plt.figure(figsize=(15, 10))\n",
    "for class_idx in range(5):\n",
    "    # Get indices of images from this class\n",
    "    indices = np.where(y_train == class_idx)[0]\n",
    "    \n",
    "    # Take the mean of LBP histograms for this class\n",
    "    mean_hist = np.mean(lbp_features_train[indices], axis=0)\n",
    "    \n",
    "    # Plot histogram\n",
    "    plt.subplot(2, 3, class_idx + 1)\n",
    "    plt.bar(range(len(mean_hist)), mean_hist)\n",
    "    plt.title(f'Mean LBP Histogram for Type {class_idx+1}')\n",
    "    plt.xlabel('LBP Bin')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Combine GLCM and LBP features\n",
    "print(\"Combining GLCM and LBP features...\")\n",
    "combined_features_train = np.hstack((glcm_features_train, lbp_features_train))\n",
    "combined_features_test = np.hstack((glcm_features_test, lbp_features_test))\n",
    "\n",
    "print(f\"Combined training features shape: {combined_features_train.shape}\")\n",
    "print(f\"Combined testing features shape: {combined_features_test.shape}\")\n",
    "\n",
    "# Standardize the features (important for SVM)\n",
    "scaler = StandardScaler()\n",
    "combined_features_train_scaled = scaler.fit_transform(combined_features_train)\n",
    "combined_features_test_scaled = scaler.transform(combined_features_test)\n",
    "\n",
    "# Initialize different classifiers\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate classifiers\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining {name} classifier...\")\n",
    "    \n",
    "    # Train the classifier\n",
    "    clf.fit(combined_features_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = clf.predict(combined_features_test_scaled)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'classifier': clf,\n",
    "        'predictions': y_pred,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "# Select the best classifier (based on accuracy)\n",
    "best_clf_name = max(results, key=lambda k: results[k]['accuracy'])\n",
    "best_clf = results[best_clf_name]['classifier']\n",
    "best_predictions = results[best_clf_name]['predictions']\n",
    "\n",
    "print(f\"\\nBest Classifier: {best_clf_name} with accuracy: {results[best_clf_name]['accuracy']:.4f}\")\n",
    "\n",
    "# Compare with individual feature sets\n",
    "print(\"\\nComparing with individual feature sets...\")\n",
    "\n",
    "# Train on GLCM features only\n",
    "clf_glcm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "glcm_features_train_scaled = scaler.fit_transform(glcm_features_train)\n",
    "glcm_features_test_scaled = scaler.transform(glcm_features_test)\n",
    "clf_glcm.fit(glcm_features_train_scaled, y_train)\n",
    "glcm_accuracy = accuracy_score(y_test, clf_glcm.predict(glcm_features_test_scaled))\n",
    "print(f\"GLCM Features Only Accuracy: {glcm_accuracy:.4f}\")\n",
    "\n",
    "# Train on LBP features only\n",
    "clf_lbp = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "lbp_features_train_scaled = scaler.fit_transform(lbp_features_train)\n",
    "lbp_features_test_scaled = scaler.transform(lbp_features_test)\n",
    "clf_lbp.fit(lbp_features_train_scaled, y_train)\n",
    "lbp_accuracy = accuracy_score(y_test, clf_lbp.predict(lbp_features_test_scaled))\n",
    "print(f\"LBP Features Only Accuracy: {lbp_accuracy:.4f}\")\n",
    "\n",
    "# Compare accuracies\n",
    "accuracies = {\n",
    "    'GLCM Only': glcm_accuracy,\n",
    "    'LBP Only': lbp_accuracy,\n",
    "    'Combined': results[best_clf_name]['accuracy']\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(accuracies.keys(), accuracies.values())\n",
    "plt.ylim(0, 1.0)\n",
    "plt.xlabel('Feature Set')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Classification Accuracy Comparison')\n",
    "for i, v in enumerate(accuracies.values()):\n",
    "    plt.text(i, v + 0.01, f\"{v:.4f}\", ha='center')\n",
    "plt.show()\n",
    "# Generate detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(y_test, best_predictions, target_names=[f'Type {i+1}' for i in range(5)])\n",
    "print(report)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[f'Type {i+1}' for i in range(5)],\n",
    "            yticklabels=[f'Type {i+1}' for i in range(5)])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate per-class metrics\n",
    "class_names = [f'Type {i+1}' for i in range(5)]\n",
    "precision = np.diag(cm) / np.sum(cm, axis=0)\n",
    "recall = np.diag(cm) / np.sum(cm, axis=1)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Plot per-class metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1_score\n",
    "}, index=class_names)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "metrics_df.plot(kind='bar', ax=plt.gca())\n",
    "plt.title('Per-Class Metrics')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(title='Metrics')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance analysis (for Random Forest)\n",
    "# FIXED: Corrected access to the Random Forest classifier\n",
    "if 'Random Forest' in results:  # Changed from 'classifiers' to 'results'\n",
    "    rf_clf = results['Random Forest']['classifier']  # Corrected dictionary access\n",
    "    \n",
    "    # Combine feature names\n",
    "    feature_names = glcm_feature_names + [f'LBP_{i}' for i in range(lbp_features_train.shape[1])]\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = rf_clf.feature_importances_\n",
    "    \n",
    "    # Sort features by importance\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    # Plot top 10 features\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.title('Feature Importances')\n",
    "    plt.bar(range(min(10, len(indices))), importances[indices[:10]], align='center')\n",
    "    plt.xticks(range(min(10, len(indices))), [feature_names[i] for i in indices[:10]], rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_predictions(X_test, y_test, y_pred, num_samples=10):\n",
    "    \"\"\"\n",
    "    Display random test images along with their true and predicted classes\n",
    "    \"\"\"\n",
    "    # Choose random indices\n",
    "    indices = np.random.choice(range(len(y_test)), min(num_samples, len(y_test)), replace=False)\n",
    "    \n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(15, 2 * num_samples))\n",
    "    \n",
    "    # For each selected index\n",
    "    for i, idx in enumerate(indices):\n",
    "        # Get the image and labels\n",
    "        image = X_test[idx]\n",
    "        true_label = y_test[idx]\n",
    "        pred_label = y_pred[idx]\n",
    "        \n",
    "        # Display the image\n",
    "        plt.subplot(num_samples, 2, 2*i + 1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(f\"True: Type {true_label+1}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Show the same image with predicted label\n",
    "        plt.subplot(num_samples, 2, 2*i + 2)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        \n",
    "        # Highlight correct/incorrect predictions\n",
    "        if true_label == pred_label:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "            \n",
    "        plt.title(f\"Predicted: Type {pred_label+1}\", color=color)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display predictions for some random test images\n",
    "print(\"Visualizing predictions on random test images:\")\n",
    "display_predictions(X_test, y_test, best_predictions, num_samples=8)\n",
    "\n",
    "# Calculate and display overall accuracy\n",
    "accuracy = accuracy_score(y_test, best_predictions)\n",
    "print(f\"Overall accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display a few examples of misclassifications\n",
    "misclassified_indices = np.where(y_test != best_predictions)[0]\n",
    "\n",
    "if len(misclassified_indices) > 0:\n",
    "    print(\"\\nExamples of misclassified images:\")\n",
    "    \n",
    "    # Choose random misclassified samples (up to 5)\n",
    "    num_examples = min(5, len(misclassified_indices))\n",
    "    sample_indices = np.random.choice(misclassified_indices, num_examples, replace=False)\n",
    "    \n",
    "    plt.figure(figsize=(15, 3 * num_examples))\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        # Display the misclassified image\n",
    "        plt.subplot(num_examples, 1, i + 1)\n",
    "        plt.imshow(X_test[idx], cmap='gray')\n",
    "        plt.title(f\"True: Type {y_test[idx]+1}, Predicted: Type {best_predictions[idx]+1}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No misclassifications found!\")\n",
    "## Conclusion\n",
    "\n",
    "#### This project demonstrated the effectiveness of combining GLCM and LBP features for texture classification. The system achieved high accuracy in classifying different fabric textures, showing its potential for real-world applications in the textile industry. Future work could explore the integration of deep learning approaches to further improve classification performance."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
